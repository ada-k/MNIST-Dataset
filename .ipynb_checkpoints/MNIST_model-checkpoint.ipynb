{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUgChF0WRi16"
   },
   "source": [
    "## Digit Recognizer\n",
    "### Learn computer vision fundamentals with the famous MNIST data\n",
    "- Defining the problem statement\n",
    "- collecting the data\n",
    "- preprocessing\n",
    "- cnn\n",
    "- ensembling predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the problem statement\n",
    "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collecting the data\n",
    "You can download the training set and test set directly from <a href = \"https://www.kaggle.com/c/digit-recognizer\">kaggle</a>\n",
    "\n",
    "Let's import the necessary header files needed for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPool2D, AvgPool2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvQ2uebVRp9e"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv.zip')\n",
    "train_df = pd.read_csv('train.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N1MJCYZRq6lq",
    "outputId": "c3f82a2f-96e1-4532-912a-8104007ce123"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SGpaXnFWsoBo",
    "outputId": "9f8e18c9-9e53-4203-c500-a78fb6dcf348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "5xWoRGHFeAJJ",
    "outputId": "4c12a54f-8b86-4deb-da4f-f24b2b26073d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0       0       0       0       0  ...         0         0         0         0\n",
       "1       0       0       0       0  ...         0         0         0         0\n",
       "2       0       0       0       0  ...         0         0         0         0\n",
       "3       0       0       0       0  ...         0         0         0         0\n",
       "4       0       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "ds_3Hbpbe6j8",
    "outputId": "d5d6c102-9cba-485e-9453-f92a4c2d6e5f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0      1       0       0       0  ...         0         0         0         0\n",
       "1      0       0       0       0  ...         0         0         0         0\n",
       "2      1       0       0       0  ...         0         0         0         0\n",
       "3      4       0       0       0  ...         0         0         0         0\n",
       "4      0       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mm3NGKPoe8UN",
    "outputId": "2574f08b-b8de-4ea5-c749-c2068b61d49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of train data is (42000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(\"The dimension of train data is\",train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sIewDBjLfDi7",
    "outputId": "7a61c7b0-74a8-4422-9330-0e914f4c9bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of test data is (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"The dimension of test data is\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "Sg5u_ogn6cL4",
    "outputId": "2a135019-5ca0-4ae0-ef22-b71a11789282"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9ba85e0d30>"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot clearly implies that the given dataset is a balanced dataset\n",
    "\n",
    "Let's split the dataset into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15Miwul4fE4S"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train_df.drop('label', axis = 1))\n",
    "Y_train = np.array(train_df['label'])\n",
    "X_test = np.array(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some of the numbers given in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E_xyXeqZ7Aj3",
    "outputId": "c148ccdc-adc2-4b52-aa79-423d616da9a5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(X_train[i][:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "\n",
    "### 3.1. Normalization\n",
    "We perform a grayscale normalization to reduce the effect of illumination's differences.\n",
    "\n",
    "Moreover the CNN converge faster on [0..1] data than on [0..255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-ZNr2UY6fGgI",
    "outputId": "8ca790e7-948c-44a7-bcdc-a7b7d5e475c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42000, 28, 28, 1)\n",
      "X_test shape: (28000, 28, 28, 1)\n",
      "Number of images in train set 42000\n",
      "Number of images in test set 28000\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('Number of images in train set', X_train.shape[0])\n",
    "print('Number of images in test set', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G35rn-awfIzM",
    "outputId": "43a1ea13-9d00-4e8e-a764-c5ddac7854a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ytrain after encoding:  (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "nclasses = Y_train.max() - Y_train.min() + 1\n",
    "Y_train = to_categorical(Y_train, num_classes = nclasses)\n",
    "print(\"Shape of ytrain after encoding: \", Y_train.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vek1dzkofLBx",
    "outputId": "b33cd65d-131e-4a49-e49b-b6a598c5065e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 28, 28, 1) (37800, 10) (4200, 28, 28, 1) (4200, 10)\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "split_pct = 0.1\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train,\n",
    "                                              Y_train, \n",
    "                                              test_size=split_pct,\n",
    "                                              random_state=seed,\n",
    "                                              shuffle=True,\n",
    "                                              stratify=Y_train\n",
    "                                             )\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Data Augmentation\n",
    "Data augmentation is a strategy that enables us to significantly increase the diversity of data available for training models, without actually collecting new data. Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks.Data Augmentation can be done easily using ImageDataGenerator in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KkOLOtEfM_4"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "          featurewise_center=False,            \n",
    "          samplewise_center=False,             \n",
    "          featurewise_std_normalization=False, \n",
    "          samplewise_std_normalization=False,  \n",
    "          zca_whitening=False,                 \n",
    "          rotation_range=10,                   \n",
    "          zoom_range = 0.1,                     \n",
    "          width_shift_range=0.1,               \n",
    "          height_shift_range=0.1,              \n",
    "          horizontal_flip=False,               \n",
    "          vertical_flip=False)                 \n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN\n",
    "\n",
    "### 4.1 Defining the model\n",
    "\n",
    "  I used lenet5 architecture with the following improvements:\n",
    "  <img src='https://miro.medium.com/max/1580/1*6C0wlygR-GAnAwheozI1KQ.png'>\n",
    "- Two stacked 3x3 filters replace the single 5x5 filters. These become nonlinear 5x5 convolutions\n",
    "- A convolution with stride 2 replaces pooling layers. These become learnable pooling layers.\n",
    "- ReLU activation replaces sigmoid.\n",
    "- Batch normalization is added\n",
    "- Dropout is added\n",
    "- More feature maps (channels) are added\n",
    "- An ensemble of 10 CNNs with bagging is used (single model gave me accuracy of .99341 after ensembling I got .99728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rq0g1Wp8fazU"
   },
   "outputs": [],
   "source": [
    "model = [0] * 10\n",
    "for i in range(10):\n",
    "\n",
    "    model[i] = Sequential()\n",
    "\n",
    "    model[i].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Dropout(0.4))\n",
    "\n",
    "    model[i].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Dropout(0.4))\n",
    "\n",
    "    model[i].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Flatten())\n",
    "    model[i].add(Dropout(0.4))\n",
    "    model[i].add(Dense(10, activation='softmax'))\n",
    "    model[i].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Training the model\n",
    "Note: Training this model will take a lot of time so i have attached the trained model in my repository "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m2Hrxcp7fdcC",
    "outputId": "ce985c6f-19a2-4b6e-eb7e-f413fda143e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN  1\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 23s 43ms/step - loss: 0.5528 - accuracy: 0.8277 - val_loss: 0.1204 - val_accuracy: 0.9606\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1518 - accuracy: 0.9538 - val_loss: 0.0506 - val_accuracy: 0.9839\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1084 - accuracy: 0.9670 - val_loss: 0.0272 - val_accuracy: 0.9923\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0920 - accuracy: 0.9719 - val_loss: 0.0538 - val_accuracy: 0.9847\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0802 - accuracy: 0.9756 - val_loss: 0.0238 - val_accuracy: 0.9939\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0735 - accuracy: 0.9773 - val_loss: 0.0338 - val_accuracy: 0.9881\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0653 - accuracy: 0.9807 - val_loss: 0.0179 - val_accuracy: 0.9952\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0602 - accuracy: 0.9824 - val_loss: 0.0395 - val_accuracy: 0.9868\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0535 - accuracy: 0.9837 - val_loss: 0.0183 - val_accuracy: 0.9942\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0493 - accuracy: 0.9856 - val_loss: 0.0186 - val_accuracy: 0.9955\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0438 - accuracy: 0.9870 - val_loss: 0.0256 - val_accuracy: 0.9931\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0446 - accuracy: 0.9869 - val_loss: 0.0173 - val_accuracy: 0.9944\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0390 - accuracy: 0.9880 - val_loss: 0.0158 - val_accuracy: 0.9960\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 0.0136 - val_accuracy: 0.9966\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 0.0158 - val_accuracy: 0.9958\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0332 - accuracy: 0.9898 - val_loss: 0.0185 - val_accuracy: 0.9950\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0340 - accuracy: 0.9898 - val_loss: 0.0163 - val_accuracy: 0.9963\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0217 - val_accuracy: 0.9952\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.0179 - val_accuracy: 0.9960\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.0137 - val_accuracy: 0.9955\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0288 - accuracy: 0.9918 - val_loss: 0.0156 - val_accuracy: 0.9966\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0146 - val_accuracy: 0.9971\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0167 - val_accuracy: 0.9950\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0185 - val_accuracy: 0.9952\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0152 - val_accuracy: 0.9963\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0146 - val_accuracy: 0.9966\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.0173 - val_accuracy: 0.9963\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0153 - val_accuracy: 0.9966\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.0173 - val_accuracy: 0.9955\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0162 - val_accuracy: 0.9958\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.0168 - val_accuracy: 0.9960\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0134 - val_accuracy: 0.9968\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0165 - val_accuracy: 0.9960\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0156 - val_accuracy: 0.9963\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.0136 - val_accuracy: 0.9968\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0133 - val_accuracy: 0.9974\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0130 - val_accuracy: 0.9976\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0150 - val_accuracy: 0.9966\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0151 - val_accuracy: 0.9966\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0149 - val_accuracy: 0.9971\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.0142 - val_accuracy: 0.9976\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0168 - val_accuracy: 0.9966\n",
      "CNN:  1   Epochs:  45   Train_accuracy:  0.99617153   Validation_accuracy:  0.9976190328598022\n",
      "CNN  2\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.5006 - accuracy: 0.8447 - val_loss: 0.2786 - val_accuracy: 0.9127\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 20s 39ms/step - loss: 0.1506 - accuracy: 0.9543 - val_loss: 0.0761 - val_accuracy: 0.9783\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1085 - accuracy: 0.9664 - val_loss: 0.0630 - val_accuracy: 0.9820\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0862 - accuracy: 0.9730 - val_loss: 0.0578 - val_accuracy: 0.9849\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.0427 - val_accuracy: 0.9876\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0691 - accuracy: 0.9787 - val_loss: 0.0427 - val_accuracy: 0.9865\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0642 - accuracy: 0.9805 - val_loss: 0.0393 - val_accuracy: 0.9897\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0611 - accuracy: 0.9812 - val_loss: 0.0480 - val_accuracy: 0.9870\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0539 - accuracy: 0.9835 - val_loss: 0.0461 - val_accuracy: 0.9870\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0519 - accuracy: 0.9839 - val_loss: 0.0317 - val_accuracy: 0.9913\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0454 - accuracy: 0.9864 - val_loss: 0.0397 - val_accuracy: 0.9892\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.0423 - val_accuracy: 0.9873\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0443 - accuracy: 0.9868 - val_loss: 0.0342 - val_accuracy: 0.9915\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.0303 - val_accuracy: 0.9929\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0356 - accuracy: 0.9895 - val_loss: 0.0455 - val_accuracy: 0.9876\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0354 - accuracy: 0.9898 - val_loss: 0.0293 - val_accuracy: 0.9929\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.0317 - val_accuracy: 0.9921\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.0291 - val_accuracy: 0.9929\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 20s 39ms/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 0.0340 - val_accuracy: 0.9915\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0334 - val_accuracy: 0.9923\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.0312 - val_accuracy: 0.9915\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.0354 - val_accuracy: 0.9918\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0257 - accuracy: 0.9924 - val_loss: 0.0325 - val_accuracy: 0.9921\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0295 - val_accuracy: 0.9929\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0319 - val_accuracy: 0.9926\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.0304 - val_accuracy: 0.9931\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0326 - val_accuracy: 0.9923\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0292 - val_accuracy: 0.9929\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 0.0283 - val_accuracy: 0.9931\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0299 - val_accuracy: 0.9934\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0269 - val_accuracy: 0.9947\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.0298 - val_accuracy: 0.9926\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0253 - val_accuracy: 0.9931\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0283 - val_accuracy: 0.9939\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.0277 - val_accuracy: 0.9942\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0288 - val_accuracy: 0.9934\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0263 - val_accuracy: 0.9937\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0269 - val_accuracy: 0.9942\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.0261 - val_accuracy: 0.9947\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0269 - val_accuracy: 0.9942\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0262 - val_accuracy: 0.9947\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0255 - val_accuracy: 0.9950\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0242 - val_accuracy: 0.9955\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0274 - val_accuracy: 0.9944\n",
      "CNN:  2   Epochs:  45   Train_accuracy:  0.9957592   Validation_accuracy:  0.9955026507377625\n",
      "CNN  3\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 23s 43ms/step - loss: 0.5054 - accuracy: 0.8442 - val_loss: 0.2703 - val_accuracy: 0.9265\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1449 - accuracy: 0.9550 - val_loss: 0.0447 - val_accuracy: 0.9876\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.1112 - accuracy: 0.9659 - val_loss: 0.0466 - val_accuracy: 0.9852\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0931 - accuracy: 0.9721 - val_loss: 0.0584 - val_accuracy: 0.9799\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0790 - accuracy: 0.9763 - val_loss: 0.0536 - val_accuracy: 0.9841\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0715 - accuracy: 0.9795 - val_loss: 0.0378 - val_accuracy: 0.9878\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0640 - accuracy: 0.9803 - val_loss: 0.0288 - val_accuracy: 0.9905\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0618 - accuracy: 0.9819 - val_loss: 0.0317 - val_accuracy: 0.9915\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 0.0244 - val_accuracy: 0.9926\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0538 - accuracy: 0.9838 - val_loss: 0.0252 - val_accuracy: 0.9931\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0484 - accuracy: 0.9855 - val_loss: 0.0284 - val_accuracy: 0.9907\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0471 - accuracy: 0.9860 - val_loss: 0.0231 - val_accuracy: 0.9923\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0468 - accuracy: 0.9863 - val_loss: 0.0327 - val_accuracy: 0.9899\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0395 - accuracy: 0.9886 - val_loss: 0.0242 - val_accuracy: 0.9934\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0406 - accuracy: 0.9877 - val_loss: 0.0217 - val_accuracy: 0.9937\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0371 - accuracy: 0.9892 - val_loss: 0.0274 - val_accuracy: 0.9921\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0376 - accuracy: 0.9886 - val_loss: 0.0200 - val_accuracy: 0.9937\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0191 - val_accuracy: 0.9952\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0312 - accuracy: 0.9909 - val_loss: 0.0251 - val_accuracy: 0.9931\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.0183 - val_accuracy: 0.9947\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.0242 - val_accuracy: 0.9937\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 0.0218 - val_accuracy: 0.9923\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0275 - accuracy: 0.9922 - val_loss: 0.0222 - val_accuracy: 0.9934\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0179 - val_accuracy: 0.9950\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.0256 - val_accuracy: 0.9931\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0192 - val_accuracy: 0.9942\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0237 - val_accuracy: 0.9944\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.0229 - val_accuracy: 0.9934\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0185 - val_accuracy: 0.9952\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0178 - val_accuracy: 0.9952\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.0182 - val_accuracy: 0.9942\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0188 - val_accuracy: 0.9952\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.0169 - val_accuracy: 0.9947\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.0188 - val_accuracy: 0.9958\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.0182 - val_accuracy: 0.9960\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0190 - val_accuracy: 0.9955\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0184 - val_accuracy: 0.9952\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0168 - val_accuracy: 0.9958\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0191 - val_accuracy: 0.9950\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0176 - val_accuracy: 0.9958\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0168 - val_accuracy: 0.9966\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0175 - val_accuracy: 0.9950\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0182 - val_accuracy: 0.9958\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0195 - val_accuracy: 0.9955\n",
      "CNN:  3   Epochs:  45   Train_accuracy:  0.9959065   Validation_accuracy:  0.9965608716011047\n",
      "CNN  4\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 24s 44ms/step - loss: 0.5098 - accuracy: 0.8416 - val_loss: 0.2295 - val_accuracy: 0.9233\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.1433 - accuracy: 0.9561 - val_loss: 0.0665 - val_accuracy: 0.9788\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.1017 - accuracy: 0.9700 - val_loss: 0.0533 - val_accuracy: 0.9873\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0902 - accuracy: 0.9731 - val_loss: 0.0477 - val_accuracy: 0.9849\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0777 - accuracy: 0.9764 - val_loss: 0.0276 - val_accuracy: 0.9907\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0687 - accuracy: 0.9793 - val_loss: 0.0318 - val_accuracy: 0.9894\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.0308 - val_accuracy: 0.9902\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 0.0369 - val_accuracy: 0.9881\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 0.0221 - val_accuracy: 0.9926\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0536 - accuracy: 0.9844 - val_loss: 0.0261 - val_accuracy: 0.9913\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 0.0228 - val_accuracy: 0.9929\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.0234 - val_accuracy: 0.9923\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.0211 - val_accuracy: 0.9931\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.0202 - val_accuracy: 0.9934\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0410 - accuracy: 0.9880 - val_loss: 0.0305 - val_accuracy: 0.9889\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.0141 - val_accuracy: 0.9947\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0362 - accuracy: 0.9891 - val_loss: 0.0160 - val_accuracy: 0.9944\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0348 - accuracy: 0.9890 - val_loss: 0.0137 - val_accuracy: 0.9950\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.0186 - val_accuracy: 0.9939\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.0174 - val_accuracy: 0.9934\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.0221 - val_accuracy: 0.9929\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0173 - val_accuracy: 0.9955\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.0174 - val_accuracy: 0.9955\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0155 - val_accuracy: 0.9950\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.0183 - val_accuracy: 0.9947\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 0.0144 - val_accuracy: 0.9947\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0177 - val_accuracy: 0.9944\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.0150 - val_accuracy: 0.9955\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0153 - val_accuracy: 0.9955\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0127 - val_accuracy: 0.9958\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0137 - val_accuracy: 0.9955\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0111 - val_accuracy: 0.9958\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0118 - val_accuracy: 0.9958\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0114 - val_accuracy: 0.9955\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0134 - val_accuracy: 0.9952\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0141 - val_accuracy: 0.9947\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0152 - val_accuracy: 0.9955\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0146 - val_accuracy: 0.9960\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0132 - val_accuracy: 0.9958\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0145 - val_accuracy: 0.9963\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0161 - val_accuracy: 0.9958\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0123 - val_accuracy: 0.9958\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0119 - val_accuracy: 0.9963\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0130 - val_accuracy: 0.9960\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0137 - val_accuracy: 0.9963\n",
      "CNN:  4   Epochs:  45   Train_accuracy:  0.9958476   Validation_accuracy:  0.9962962865829468\n",
      "CNN  5\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 23s 43ms/step - loss: 0.5041 - accuracy: 0.8434 - val_loss: 0.3327 - val_accuracy: 0.9124\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1434 - accuracy: 0.9556 - val_loss: 0.0495 - val_accuracy: 0.9862\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1068 - accuracy: 0.9677 - val_loss: 0.0972 - val_accuracy: 0.9730\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0910 - accuracy: 0.9726 - val_loss: 0.0284 - val_accuracy: 0.9910\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0797 - accuracy: 0.9763 - val_loss: 0.0322 - val_accuracy: 0.9899\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0689 - accuracy: 0.9790 - val_loss: 0.0349 - val_accuracy: 0.9907\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0641 - accuracy: 0.9812 - val_loss: 0.0371 - val_accuracy: 0.9886\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0599 - accuracy: 0.9819 - val_loss: 0.0230 - val_accuracy: 0.9934\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0539 - accuracy: 0.9835 - val_loss: 0.0260 - val_accuracy: 0.9913\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0503 - accuracy: 0.9849 - val_loss: 0.0279 - val_accuracy: 0.9921\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0485 - accuracy: 0.9857 - val_loss: 0.0209 - val_accuracy: 0.9939\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0453 - accuracy: 0.9868 - val_loss: 0.0218 - val_accuracy: 0.9931\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 0.0178 - val_accuracy: 0.9958\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 0.0243 - val_accuracy: 0.9929\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.0189 - val_accuracy: 0.9942\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0365 - accuracy: 0.9885 - val_loss: 0.0158 - val_accuracy: 0.9944\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0351 - accuracy: 0.9899 - val_loss: 0.0174 - val_accuracy: 0.9950\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0193 - val_accuracy: 0.9944\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.0161 - val_accuracy: 0.9950\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 0.0139 - val_accuracy: 0.9960\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.0148 - val_accuracy: 0.9950\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0275 - accuracy: 0.9914 - val_loss: 0.0122 - val_accuracy: 0.9966\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0141 - val_accuracy: 0.9966\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0112 - val_accuracy: 0.9974\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0130 - val_accuracy: 0.9966\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0121 - val_accuracy: 0.9963\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0123 - val_accuracy: 0.9968\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 0.0107 - val_accuracy: 0.9976\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0110 - val_accuracy: 0.9963\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0121 - val_accuracy: 0.9955\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0097 - val_accuracy: 0.9974\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.0102 - val_accuracy: 0.9971\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0129 - val_accuracy: 0.9955\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0098 - val_accuracy: 0.9974\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0116 - val_accuracy: 0.9963\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0086 - val_accuracy: 0.9976\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0107 - val_accuracy: 0.9971\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0098 - val_accuracy: 0.9974\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0083 - val_accuracy: 0.9976\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0106 - val_accuracy: 0.9971\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0112 - val_accuracy: 0.9963\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0085 - val_accuracy: 0.9981\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0093 - val_accuracy: 0.9971\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.0099 - val_accuracy: 0.9968\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0110 - val_accuracy: 0.9958\n",
      "CNN:  5   Epochs:  45   Train_accuracy:  0.9959031   Validation_accuracy:  0.9981481432914734\n",
      "CNN  6\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.5046 - accuracy: 0.8438 - val_loss: 1.5580 - val_accuracy: 0.5749\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1493 - accuracy: 0.9549 - val_loss: 0.0553 - val_accuracy: 0.9839\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1043 - accuracy: 0.9682 - val_loss: 0.0414 - val_accuracy: 0.9902\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0895 - accuracy: 0.9729 - val_loss: 0.0486 - val_accuracy: 0.9862\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0758 - accuracy: 0.9774 - val_loss: 0.0347 - val_accuracy: 0.9907\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0702 - accuracy: 0.9797 - val_loss: 0.0346 - val_accuracy: 0.9899\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0618 - accuracy: 0.9807 - val_loss: 0.0419 - val_accuracy: 0.9881\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0620 - accuracy: 0.9815 - val_loss: 0.0410 - val_accuracy: 0.9892\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0537 - accuracy: 0.9838 - val_loss: 0.0325 - val_accuracy: 0.9921\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0516 - accuracy: 0.9847 - val_loss: 0.0408 - val_accuracy: 0.9902\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0488 - accuracy: 0.9855 - val_loss: 0.0329 - val_accuracy: 0.9907\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 0.0277 - val_accuracy: 0.9942\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 0.0283 - val_accuracy: 0.9918\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0365 - accuracy: 0.9894 - val_loss: 0.0265 - val_accuracy: 0.9939\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.0248 - val_accuracy: 0.9934\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0342 - accuracy: 0.9897 - val_loss: 0.0270 - val_accuracy: 0.9929\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.0308 - val_accuracy: 0.9913\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 0.0254 - val_accuracy: 0.9929\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 0.0232 - val_accuracy: 0.9942\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0292 - accuracy: 0.9910 - val_loss: 0.0259 - val_accuracy: 0.9934\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0232 - val_accuracy: 0.9950\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0244 - val_accuracy: 0.9931\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0240 - val_accuracy: 0.9947\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.0228 - val_accuracy: 0.9950\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0237 - val_accuracy: 0.9950\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.0235 - val_accuracy: 0.9944\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0241 - val_accuracy: 0.9939\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0216 - val_accuracy: 0.9955\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0233 - val_accuracy: 0.9942\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.0247 - val_accuracy: 0.9942\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0247 - val_accuracy: 0.9942\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.0251 - val_accuracy: 0.9937\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0247 - val_accuracy: 0.9939\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0253 - val_accuracy: 0.9937\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0269 - val_accuracy: 0.9934\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0244 - val_accuracy: 0.9931\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0246 - val_accuracy: 0.9944\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0232 - val_accuracy: 0.9947\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.0220 - val_accuracy: 0.9950\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0215 - val_accuracy: 0.9952\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 0.0212 - val_accuracy: 0.9944\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0200 - val_accuracy: 0.9958\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0218 - val_accuracy: 0.9944\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0213 - val_accuracy: 0.9952\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0225 - val_accuracy: 0.9950\n",
      "CNN:  6   Epochs:  45   Train_accuracy:  0.99608314   Validation_accuracy:  0.9957671761512756\n",
      "CNN  7\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 23s 42ms/step - loss: 0.4680 - accuracy: 0.8554 - val_loss: 1.0555 - val_accuracy: 0.6770\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1394 - accuracy: 0.9580 - val_loss: 0.0496 - val_accuracy: 0.9847\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.1063 - accuracy: 0.9676 - val_loss: 0.0507 - val_accuracy: 0.9847\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0851 - accuracy: 0.9744 - val_loss: 0.0359 - val_accuracy: 0.9894\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0764 - accuracy: 0.9779 - val_loss: 0.0404 - val_accuracy: 0.9889\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0672 - accuracy: 0.9794 - val_loss: 0.0339 - val_accuracy: 0.9894\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0601 - accuracy: 0.9818 - val_loss: 0.0277 - val_accuracy: 0.9923\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0530 - accuracy: 0.9838 - val_loss: 0.0315 - val_accuracy: 0.9913\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0522 - accuracy: 0.9839 - val_loss: 0.0260 - val_accuracy: 0.9913\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0233 - val_accuracy: 0.9923\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0467 - accuracy: 0.9861 - val_loss: 0.0350 - val_accuracy: 0.9876\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0447 - accuracy: 0.9868 - val_loss: 0.0296 - val_accuracy: 0.9915\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0448 - accuracy: 0.9871 - val_loss: 0.0326 - val_accuracy: 0.9897\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0388 - accuracy: 0.9885 - val_loss: 0.0233 - val_accuracy: 0.9937\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0371 - accuracy: 0.9893 - val_loss: 0.0243 - val_accuracy: 0.9947\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.0200 - val_accuracy: 0.9958\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 0.0224 - val_accuracy: 0.9947\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.0241 - val_accuracy: 0.9929\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0193 - val_accuracy: 0.9952\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.0210 - val_accuracy: 0.9958\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.0220 - val_accuracy: 0.9942\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 0.0217 - val_accuracy: 0.9939\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0202 - val_accuracy: 0.9958\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0188 - val_accuracy: 0.9960\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.0189 - val_accuracy: 0.9958\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0178 - val_accuracy: 0.9960\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.0214 - val_accuracy: 0.9947\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0206 - val_accuracy: 0.9955\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0170 - val_accuracy: 0.9958\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0202 - val_accuracy: 0.9960\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 20s 39ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.0202 - val_accuracy: 0.9963\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0219 - val_accuracy: 0.9950\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0205 - val_accuracy: 0.9952\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0241 - val_accuracy: 0.9952\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.0213 - val_accuracy: 0.9952\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.0199 - val_accuracy: 0.9960\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0230 - val_accuracy: 0.9955\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0206 - val_accuracy: 0.9958\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0217 - val_accuracy: 0.9968\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0201 - val_accuracy: 0.9960\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0214 - val_accuracy: 0.9958\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0210 - val_accuracy: 0.9952\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0201 - val_accuracy: 0.9963\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0191 - val_accuracy: 0.9968\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0213 - val_accuracy: 0.9966\n",
      "CNN:  7   Epochs:  45   Train_accuracy:  0.9961421   Validation_accuracy:  0.9968253970146179\n",
      "CNN  8\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 22s 42ms/step - loss: 0.4984 - accuracy: 0.8469 - val_loss: 0.2083 - val_accuracy: 0.9291\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1353 - accuracy: 0.9586 - val_loss: 0.0534 - val_accuracy: 0.9839\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.1036 - accuracy: 0.9693 - val_loss: 0.0406 - val_accuracy: 0.9889\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0886 - accuracy: 0.9733 - val_loss: 0.0372 - val_accuracy: 0.9881\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0740 - accuracy: 0.9770 - val_loss: 0.0269 - val_accuracy: 0.9923\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 0.0288 - val_accuracy: 0.9913\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 0.0264 - val_accuracy: 0.9921\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 0.0329 - val_accuracy: 0.9907\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0555 - accuracy: 0.9835 - val_loss: 0.0303 - val_accuracy: 0.9923\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 0.0247 - val_accuracy: 0.9931\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0510 - accuracy: 0.9850 - val_loss: 0.0291 - val_accuracy: 0.9923\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0442 - accuracy: 0.9866 - val_loss: 0.0337 - val_accuracy: 0.9899\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0417 - accuracy: 0.9874 - val_loss: 0.0268 - val_accuracy: 0.9931\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0429 - accuracy: 0.9873 - val_loss: 0.0232 - val_accuracy: 0.9923\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0388 - accuracy: 0.9880 - val_loss: 0.0287 - val_accuracy: 0.9931\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.0221 - val_accuracy: 0.9939\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0276 - val_accuracy: 0.9929\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.0201 - val_accuracy: 0.9931\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0225 - val_accuracy: 0.9944\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0225 - val_accuracy: 0.9929\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 0.0218 - val_accuracy: 0.9942\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.0203 - val_accuracy: 0.9950\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.0258 - val_accuracy: 0.9937\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 0.0245 - val_accuracy: 0.9923\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.0231 - val_accuracy: 0.9944\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.0209 - val_accuracy: 0.9942\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.0229 - val_accuracy: 0.9931\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0211 - val_accuracy: 0.9939\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0223 - val_accuracy: 0.9939\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.0178 - val_accuracy: 0.9944\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.0197 - val_accuracy: 0.9942\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.0200 - val_accuracy: 0.9944\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0187 - val_accuracy: 0.9944\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0198 - val_accuracy: 0.9942\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.0194 - val_accuracy: 0.9955\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0199 - val_accuracy: 0.9942\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0191 - val_accuracy: 0.9952\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0187 - val_accuracy: 0.9947\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.0213 - val_accuracy: 0.9944\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0204 - val_accuracy: 0.9952\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0203 - val_accuracy: 0.9952\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0174 - val_accuracy: 0.9955\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0172 - val_accuracy: 0.9955\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0164 - val_accuracy: 0.9955\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0166 - val_accuracy: 0.9947\n",
      "CNN:  8   Epochs:  45   Train_accuracy:  0.99617153   Validation_accuracy:  0.9955026507377625\n",
      "CNN  9\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 23s 43ms/step - loss: 0.4957 - accuracy: 0.8492 - val_loss: 0.1040 - val_accuracy: 0.9664\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1420 - accuracy: 0.9578 - val_loss: 0.0384 - val_accuracy: 0.9857\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.1012 - accuracy: 0.9698 - val_loss: 0.0459 - val_accuracy: 0.9841\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0872 - accuracy: 0.9736 - val_loss: 0.0263 - val_accuracy: 0.9913\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0797 - accuracy: 0.9764 - val_loss: 0.0277 - val_accuracy: 0.9913\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0688 - accuracy: 0.9796 - val_loss: 0.0196 - val_accuracy: 0.9937\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0622 - accuracy: 0.9814 - val_loss: 0.0161 - val_accuracy: 0.9952\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0569 - accuracy: 0.9836 - val_loss: 0.0159 - val_accuracy: 0.9958\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0568 - accuracy: 0.9829 - val_loss: 0.0153 - val_accuracy: 0.9944\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0491 - accuracy: 0.9852 - val_loss: 0.0187 - val_accuracy: 0.9944\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 0.0158 - val_accuracy: 0.9950\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.0115 - val_accuracy: 0.9966\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 0.0148 - val_accuracy: 0.9952\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.0140 - val_accuracy: 0.9947\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0396 - accuracy: 0.9886 - val_loss: 0.0102 - val_accuracy: 0.9966\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0366 - accuracy: 0.9891 - val_loss: 0.0133 - val_accuracy: 0.9950\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0364 - accuracy: 0.9892 - val_loss: 0.0166 - val_accuracy: 0.9947\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0117 - val_accuracy: 0.9955\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.0126 - val_accuracy: 0.9958\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.0105 - val_accuracy: 0.9966\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.0109 - val_accuracy: 0.9966\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.0137 - val_accuracy: 0.9958\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.0093 - val_accuracy: 0.9974\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.0098 - val_accuracy: 0.9971\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0101 - val_accuracy: 0.9976\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.0103 - val_accuracy: 0.9971\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0102 - val_accuracy: 0.9968\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.0100 - val_accuracy: 0.9958\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0122 - val_accuracy: 0.9960\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0103 - val_accuracy: 0.9971\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.0085 - val_accuracy: 0.9974\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0101 - val_accuracy: 0.9966\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0093 - val_accuracy: 0.9971\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0093 - val_accuracy: 0.9966\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0080 - val_accuracy: 0.9979\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0103 - val_accuracy: 0.9968\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0088 - val_accuracy: 0.9971\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0076 - val_accuracy: 0.9974\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.0103 - val_accuracy: 0.9963\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0105 - val_accuracy: 0.9968\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0087 - val_accuracy: 0.9968\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0092 - val_accuracy: 0.9966\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.0090 - val_accuracy: 0.9979\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0082 - val_accuracy: 0.9976\n",
      "CNN:  9   Epochs:  45   Train_accuracy:  0.9956414   Validation_accuracy:  0.9978836178779602\n",
      "CNN  10\n",
      "Epoch 1/45\n",
      "531/531 [==============================] - 22s 41ms/step - loss: 0.5009 - accuracy: 0.8467 - val_loss: 0.2436 - val_accuracy: 0.9212\n",
      "Epoch 2/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.1497 - accuracy: 0.9545 - val_loss: 0.0459 - val_accuracy: 0.9860\n",
      "Epoch 3/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.1036 - accuracy: 0.9676 - val_loss: 0.0403 - val_accuracy: 0.9892\n",
      "Epoch 4/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0907 - accuracy: 0.9723 - val_loss: 0.0322 - val_accuracy: 0.9910\n",
      "Epoch 5/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.0379 - val_accuracy: 0.9899\n",
      "Epoch 6/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0722 - accuracy: 0.9784 - val_loss: 0.0301 - val_accuracy: 0.9910\n",
      "Epoch 7/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0595 - accuracy: 0.9819 - val_loss: 0.0250 - val_accuracy: 0.9921\n",
      "Epoch 8/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0594 - accuracy: 0.9824 - val_loss: 0.0328 - val_accuracy: 0.9905\n",
      "Epoch 9/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0531 - accuracy: 0.9842 - val_loss: 0.0517 - val_accuracy: 0.9873\n",
      "Epoch 10/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0514 - accuracy: 0.9850 - val_loss: 0.0293 - val_accuracy: 0.9910\n",
      "Epoch 11/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0475 - accuracy: 0.9851 - val_loss: 0.0233 - val_accuracy: 0.9913\n",
      "Epoch 12/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0450 - accuracy: 0.9865 - val_loss: 0.0225 - val_accuracy: 0.9934\n",
      "Epoch 13/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 0.0245 - val_accuracy: 0.9937\n",
      "Epoch 14/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.0220 - val_accuracy: 0.9944\n",
      "Epoch 15/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0369 - accuracy: 0.9885 - val_loss: 0.0270 - val_accuracy: 0.9923\n",
      "Epoch 16/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0371 - accuracy: 0.9893 - val_loss: 0.0230 - val_accuracy: 0.9939\n",
      "Epoch 17/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.0217 - val_accuracy: 0.9939\n",
      "Epoch 18/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 0.0191 - val_accuracy: 0.9939\n",
      "Epoch 19/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.0196 - val_accuracy: 0.9944\n",
      "Epoch 20/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.0242 - val_accuracy: 0.9918\n",
      "Epoch 21/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0190 - val_accuracy: 0.9944\n",
      "Epoch 22/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.0182 - val_accuracy: 0.9950\n",
      "Epoch 23/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0204 - val_accuracy: 0.9955\n",
      "Epoch 24/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 0.0174 - val_accuracy: 0.9952\n",
      "Epoch 25/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.0163 - val_accuracy: 0.9958\n",
      "Epoch 26/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.0186 - val_accuracy: 0.9950\n",
      "Epoch 27/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.0149 - val_accuracy: 0.9958\n",
      "Epoch 28/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0140 - val_accuracy: 0.9950\n",
      "Epoch 29/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0132 - val_accuracy: 0.9950\n",
      "Epoch 30/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.0195 - val_accuracy: 0.9950\n",
      "Epoch 31/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0178 - val_accuracy: 0.9952\n",
      "Epoch 32/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0145 - val_accuracy: 0.9950\n",
      "Epoch 33/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0166 - val_accuracy: 0.9958\n",
      "Epoch 34/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0182 - val_accuracy: 0.9947\n",
      "Epoch 35/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.0201 - val_accuracy: 0.9944\n",
      "Epoch 36/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0159 - val_accuracy: 0.9950\n",
      "Epoch 37/45\n",
      "531/531 [==============================] - 20s 39ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.0163 - val_accuracy: 0.9955\n",
      "Epoch 38/45\n",
      "531/531 [==============================] - 21s 40ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.0163 - val_accuracy: 0.9944\n",
      "Epoch 39/45\n",
      "531/531 [==============================] - 20s 39ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0162 - val_accuracy: 0.9955\n",
      "Epoch 40/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0187 - val_accuracy: 0.9955\n",
      "Epoch 41/45\n",
      "531/531 [==============================] - 20s 39ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0167 - val_accuracy: 0.9963\n",
      "Epoch 42/45\n",
      "531/531 [==============================] - 20s 38ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0169 - val_accuracy: 0.9952\n",
      "Epoch 43/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0165 - val_accuracy: 0.9952\n",
      "Epoch 44/45\n",
      "531/531 [==============================] - 20s 39ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0158 - val_accuracy: 0.9958\n",
      "Epoch 45/45\n",
      "531/531 [==============================] - 21s 39ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
      "CNN:  10   Epochs:  45   Train_accuracy:  0.9959915   Validation_accuracy:  0.9962962865829468\n"
     ]
    }
   ],
   "source": [
    "s = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "model_log = [0] * 10\n",
    "epochs = 45\n",
    "for j in range(10):\n",
    "    print(\"CNN \",j+1)\n",
    "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n",
    "    model_log[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
    "        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n",
    "        validation_data = (X_val2,Y_val2), callbacks=[s], verbose=1)\n",
    "    print(\"CNN: \",j+1,\" \",\"Epochs: \",epochs,\" \",\"Train_accuracy: \",max(model_log[j].history['accuracy']),\" \",\"Validation_accuracy: \",max(model_log[j].history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualizing train and validation set results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the train set and validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "MWbdVcPNNz9o",
    "outputId": "54deb584-2444-4479-bb64-261aba839c6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9bb20cd390>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_log[0].history['accuracy'],label = 'ACCURACY')\n",
    "plt.plot(model_log[0].history['val_accuracy'],label = 'VALIDATION ACCURACY')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot it is clear that accuracy approaches towards 1. In this case (1st model) validation accuracy seems to be slightly greater than training accuracy\n",
    "\n",
    "Let's visualize the loss in train set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "mZqk1FLQ2oCN",
    "outputId": "980e0196-e832-4a83-fba2-6feb6b8f1b02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9ba96ef7b8>"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_log[0].history['loss'],label = 'TRAINING LOSS')\n",
    "plt.plot(model_log[0].history['val_loss'],label = 'VALIDATION LOSS')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensembling predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRPsn9oU3alw"
   },
   "outputs": [],
   "source": [
    "results = np.zeros( (X_test.shape[0],10) ) \n",
    "for j in range(10):\n",
    "    results = results + model[j].predict(X_test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"/Ensemble_predictions.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this article, we explored a dataset hosted by <a href=\"http://kaggle.com\">Kaggle</a>.\n",
    "\n",
    "- Defining the problem statement\n",
    "- loading the data\n",
    "- preprocessing\n",
    "- cnn\n",
    "- ensembling predictions\n",
    "\n",
    "I trained a simple lenet 5 and got an accuracy of .98814. After that I followed this <a href = \" https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist\">Kernel</a> and  made modifications in lenet 5 architecutre and got an accuracy of .99200. Ensembling and data augmentation made my accuracy jump to .99728.\n",
    "\n",
    "This entire notebook has been compiled on <a href = \"https://colab.research.google.com/notebooks/intro.ipynb#recent=true\">google collab</a>\n",
    "\n",
    " In my repository I am attaching my trained model as training takes a lot of time(it took me 3hrs in google collab). If you are struggling importing that model then please follow my another notebook on this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. References\n",
    "\n",
    "- https://www.youtube.com/watch?v=KdhphuuHyxA\n",
    "- https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
